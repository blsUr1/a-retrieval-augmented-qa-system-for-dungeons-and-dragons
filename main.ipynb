{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea270d71",
   "metadata": {},
   "source": [
    "# RAG-based Q&A on D&D #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7138d4",
   "metadata": {},
   "source": [
    "# 1. Pulling the API-data from the website #\n",
    "\n",
    "The first step is to pull the information from the api-website (link: https://www.dnd5eapi.co/api/2014) and save the entries from the tables into dictionaries, so that they can then be written to json files and become permeated information that is indepentent from the api and its availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All needed modules and installments\n",
    "%pip install -U datasets huggingface_hub fsspec\n",
    "%pip -m spacy download en_core_web_sm\n",
    "%pip install haystack-ai\n",
    "%pip install google-genai-haystack\n",
    "%pip install \"sentence-transformers>=4.1.0\"\n",
    "%pip install \"fsspec==2023.9.2\"\n",
    "%pip install \"sentence-transformers>=4.1.0\" \"huggingface_hub>=0.23.0\"\n",
    "%pip install markdown-it-py mdit_plain pypdf\n",
    "%pip install transformers[torch,sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7af5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\susib\\anaconda3\\envs\\phython_fallstudien\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# All needed imports\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack import Document\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever, InMemoryBM25Retriever\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.generators.google_genai import GoogleGenAIChatGenerator\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.rankers import SentenceTransformersSimilarityRanker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there is a specific rate limit of 10k requests per second, code to respect that rate limit including a buffer were integrated:\n",
    "MAX_REQUESTS_PER_SECOND = 5000\n",
    "DELAY = 1 / MAX_REQUESTS_PER_SECOND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the website link and code to generally acces the api and display the different tables that are supposed to get saved.\n",
    "# This general code was taken from the api-website to get an understanding of the access.\n",
    "url = \"https://www.dnd5eapi.co/api/2014/\"\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'Accept': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "answer_whole = response.text\n",
    "print(answer_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35315563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When looking at some of the textual entries, there were multiple entries containing '#', '\\n' and multiple whitespaces so they were all removed.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text_p = 'How does this work?'\n",
    "\n",
    "# This method was taken from our exercise class:\n",
    "def remove_xml_tags(review_text):\n",
    "    return BeautifulSoup(review_text, \"html.parser\").text\n",
    "\n",
    "# This method was also inspired from the one in our class but changed so if fits the context.\n",
    "def preprocess_text(text):\n",
    "    # Some of the handled descriptions were lists of strings, so it was checked whether that was the case for each entry string.\n",
    "    # If they were in a list, the entries were joined to one single string.\n",
    "    if isinstance(text,list):\n",
    "        text = ' '.join(text)  \n",
    "    # Possible html tags were removed\n",
    "    free_text = remove_xml_tags(text)\n",
    "\n",
    "    # The unwanted characters were removed - lowering the text and removing stopwords and punctuation was not done, because the llm later needs to restrucutre the given text into an response,\n",
    "    # and to keep the 'sense' of the description, the stopwords weren't removed.\n",
    "    # In order to remove these characters, they were filtered by a regex.\n",
    "    free_text = re.sub(r\"[#_*\\\\(\\)\\n]\", \"\", text)\n",
    "    free_text = re.sub(r\"[\\s]{2,}\", \" \", free_text)\n",
    "    free_text = re.sub(r\"[{2,}-]\", \" \", free_text)\n",
    "    return free_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d21128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These tables were all handled at once, because when looking at them, they had the same basic structure:\n",
    "list_of_indices = ['conditions','damage-types','magic-schools','rule-sections','weapon-properties']\n",
    "# Empty dictionaries to later store the information were initialized:\n",
    "dict_of_conditions = {}\n",
    "dict_of_damage_types = {}\n",
    "dict_of_magic_schools = {}\n",
    "dict_of_rule_sections = {}\n",
    "dict_of_weapon_properties = {}\n",
    "\n",
    "# This method takes the str-input that functions as a identifier for the dict and the indexing word.\n",
    "def create_dict(type):\n",
    "    # A dictionary that holds the response data.\n",
    "    dict_of_response_data = {}\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    url = \"https://www.dnd5eapi.co/api/2014/\"+type\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    resp = response.json()\n",
    "    # Every entry in the results is walked through and information such as 'name' and 'description' is saved in a variable.\n",
    "    for entry in resp['results']:\n",
    "        response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "        resp2 = response2.json()\n",
    "        # They are joined in a dictionary specific for each entry in the response list.\n",
    "        response_data = {\n",
    "            'name': entry['name'].lower(),\n",
    "            'desc': \"\".join(preprocess_text(resp2['desc']))\n",
    "        }\n",
    "        # For every index in the list an dictionary entry is added to the returned dictionary.\n",
    "        dict_of_response_data[entry['index']] = response_data\n",
    "    return dict_of_response_data\n",
    "\n",
    "# All similar dictionaries are created below:\n",
    "dict_of_conditions = create_dict(list_of_indices[0])\n",
    "dict_of_damage_types = create_dict(list_of_indices[1])\n",
    "dict_of_magic_schools = create_dict(list_of_indices[2])\n",
    "dict_of_rule_sections = create_dict(list_of_indices[3])\n",
    "dict_of_weapon_properties = create_dict(list_of_indices[4])\n",
    "# An example from above:\n",
    "pprint.pprint(dict_of_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfa814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the possible skills:\n",
    "url = \"https://www.dnd5eapi.co/api/2014/skills\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_skills = {}\n",
    "skill_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "     name = entry['name']\n",
    "\n",
    "     time.sleep(DELAY)\n",
    "\n",
    "     response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "     resp2 = response2.json()\n",
    "\n",
    "     skill_data = {\n",
    "         'name': name,\n",
    "         'desc': preprocess_text(resp2['desc']),\n",
    "         'ability_score': resp2['ability_score']\n",
    "    }\n",
    "     \n",
    "     dict_of_skills[entry['index']] = skill_data\n",
    "pprint.pprint(dict_of_skills)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the possible feats. The API contain in this and the background table only one entry due to Copyright reasons.\n",
    "url = \"https://www.dnd5eapi.co/api/2014/feats\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_feats = {}\n",
    "feat_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "     name = entry['name']\n",
    "\n",
    "     time.sleep(DELAY)\n",
    "\n",
    "     response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "     resp2 = response2.json()\n",
    "\n",
    "     feat_data = {\n",
    "         'name': name,\n",
    "         'desc': preprocess_text(resp2['desc'])\n",
    "    }\n",
    "     if resp2.get('prerequisites'):\n",
    "          feat_data['prerequisites']= [{'ability_score': item['ability_score']['name'], 'minimum_score':item['minimum_score'] }for item in resp2['prerequisites']]\n",
    "     \n",
    "     dict_of_feats[entry['index']] = feat_data\n",
    "pprint.pprint(dict_of_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5abc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the ability score table from the API:\n",
    "url = \"https://www.dnd5eapi.co/api/2014/ability-scores\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_ability_scores = {}\n",
    "ability_score_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "     name = entry['name']\n",
    "\n",
    "     time.sleep(DELAY)\n",
    "     \n",
    "     response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "     resp2 = response2.json()\n",
    "\n",
    "     ability_score_data = {\n",
    "         'abbreviation': name,\n",
    "         'name': resp2['full_name'],\n",
    "         'desc': preprocess_text(resp2['desc'])\n",
    "    }\n",
    "     if resp2.get('skills'):\n",
    "          ability_score_data['skills']= [item['name'] for item in resp2['skills']]\n",
    "     \n",
    "     dict_of_ability_scores[entry['index']] = ability_score_data\n",
    "pprint.pprint(dict_of_ability_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97863657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cel handles the language table from the API:\n",
    "url = \"https://www.dnd5eapi.co/api/2014/languages\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_languages = {}\n",
    "language_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "     name = entry['name']\n",
    "\n",
    "     time.sleep(DELAY)\n",
    "     \n",
    "     response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "     resp2 = response2.json()\n",
    "\n",
    "     language_data = {\n",
    "         'name': name,\n",
    "         'type': resp2['type'],\n",
    "         'typical_speakers': resp2['typical_speakers']\n",
    "    }\n",
    "     if resp2.get('script'):\n",
    "          language_data['script']= resp2['script']\n",
    "     \n",
    "     dict_of_languages[entry['index']] = language_data\n",
    "pprint.pprint(dict_of_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc79df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the different classes there are in the API:\n",
    "url = \"https://www.dnd5eapi.co/api/2014/classes\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_classes = {}\n",
    "class_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "     name = entry['name']\n",
    "\n",
    "     time.sleep(DELAY)\n",
    "\n",
    "     response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "     resp2 = response2.json()\n",
    "\n",
    "     class_data = {\n",
    "         'name': name,\n",
    "         'hit_die': resp2['hit_die']\n",
    "    }\n",
    "     # This structure tries to identify whether certain 'variables' exist in the table,\n",
    "     # they follow the same structure but some don't have values stored in them and these ones are not supposed to be saved, so there is less data.\n",
    "     if resp2.get('proficiency_choices'):\n",
    "         class_data['proficiency_choices'] = preprocess_text([item['desc'] for item in resp2['proficiency_choices']])\n",
    "\n",
    "     if resp2.get('proficiencies'):\n",
    "         class_data['proficiencies'] = [item['name'] for item in resp2['proficiencies']]\n",
    "\n",
    "     if resp2.get('saving_throws'):\n",
    "         class_data['saving_throws'] = [item['name'] for item in resp2['saving_throws']]\n",
    "     \n",
    "     if resp2.get('starting_equipment'):\n",
    "         class_data['starting_equipment'] = [{'name': item['equipment']['name'], 'quantity': item['quantity']} for item in resp2['starting_equipment']]\n",
    "     \n",
    "     if resp2.get('starting_equipment_options'):\n",
    "         class_data['starting_equipment_options'] = preprocess_text([item['desc'] for item in resp2['starting_equipment_options']])\n",
    "     \n",
    "\n",
    "     time.sleep(DELAY)\n",
    "     \n",
    "     # This table includes annother link for each class the link to this varaible looks like this f.ex. 'https://www.dnd5eapi.co/api/2014/classes/barbarian/levels'\n",
    "     response3 = requests.request(\"GET\", url+f\"/{entry['index']}/levels\", headers=headers, data=payload)\n",
    "     resp3 = response3.json()\n",
    "\n",
    "     level_changes = []\n",
    "     # for every entry there are changes to the character and these changes will be saved in the level_changes list and later added to the\n",
    "     # class structure above under the key \"class_levels\":\n",
    "     for lvl_entries in resp3:\n",
    "          level_dict = {\n",
    "               'level': lvl_entries['level'],\n",
    "               'ability_score_bonuses': lvl_entries['ability_score_bonuses'],\n",
    "               'proficienciy_bonus': lvl_entries['prof_bonus'],\n",
    "               'features': [item['name'] for item in lvl_entries['features']],\n",
    "               'class_specific': lvl_entries['class_specific']\n",
    "          }\n",
    "          level_changes.append(level_dict)\n",
    "\n",
    "     if resp2.get('class_levels'):\n",
    "         class_data['class_levels'] = level_changes\n",
    "     \n",
    "     if resp2.get('multi_classing'):\n",
    "         multi_class_dict = {}\n",
    "         if resp2['multi_classing'].get('prerequisites'):\n",
    "            prerequisites = [{'ability': item['ability_score']['name'], 'minimum_score': item['minimum_score']} for item in resp2['multi_classing']['prerequisites']]\n",
    "            multi_class_dict['prerequisites'] = prerequisites\n",
    "         if resp2['multi_classing'].get('proficiencies'):\n",
    "            multi_class_dict['proficienies'] = [item['name'] for item in resp2['multi_classing']['proficiencies']]\n",
    "         class_data['multi_classing'] = [multi_class_dict]\n",
    "     \n",
    "     if resp2.get('subclasses'):\n",
    "         class_data['subclasses'] = [item['name'] for item in resp2['subclasses']]\n",
    "     \n",
    "\n",
    "     # At the end all of indices are saved into the dictionary.\n",
    "     dict_of_classes[entry['index']] = class_data\n",
    "pprint.pprint(dict_of_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the subclasses the player can be in the API:\n",
    "url = \"https://www.dnd5eapi.co/api/2014/subclasses\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_subclasses = {}\n",
    "subclass_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "     name = entry['name']\n",
    "\n",
    "     time.sleep(DELAY)\n",
    "\n",
    "     response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "     resp2 = response2.json()\n",
    "\n",
    "     subclass_data = {\n",
    "         'name': name,\n",
    "         'class': resp2['class']['name'],\n",
    "         'subclass_flavor': resp2['subclass_flavor'],\n",
    "         'desc': preprocess_text(resp2['desc'])\n",
    "    }\n",
    "     \n",
    "     time.sleep(DELAY)\n",
    "     \n",
    "      # This table includes annother link for each class the link to this varaible looks like this f.ex. 'https://www.dnd5eapi.co/api/2014/classes/barbarian/levels'\n",
    "     response3 = requests.request(\"GET\", url+f\"/{entry['index']}/levels\", headers=headers, data=payload)\n",
    "     resp3 = response3.json()\n",
    "\n",
    "     sublevel_changes = []\n",
    "\n",
    "     for lvl_entries in resp3:\n",
    "          sublevel_dict = {\n",
    "               'level': lvl_entries['level'],\n",
    "               'features': [item['name'] for item in lvl_entries['features']]\n",
    "          }\n",
    "          sublevel_changes.append(level_dict)\n",
    "\n",
    "     if resp2.get('subclass_levels'):\n",
    "         subclass_data['subclass_levels'] = level_changes\n",
    "     # At the end all of indices are saved into the dictionary.\n",
    "     dict_of_subclasses[entry['index']] = subclass_data\n",
    "pprint.pprint(dict_of_subclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the establishment of the trait dictionary. This cell and all the ones below concerning the api follow the same structure in general:\n",
    "# 1. The information is pulled out.\n",
    "# 2. The relevant information is saved in a dictionary (entries like 'url' were ignored, because they don't contain relevant information)\n",
    "# 3. The information for each entry gets saved in a bigger dictionary.\n",
    "\n",
    "url = \"https://www.dnd5eapi.co/api/2014/traits\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_traits = {}\n",
    "trait_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    trait_data = {\n",
    "         'name': name,\n",
    "          'desc': \"\".join(preprocess_text(resp2['desc']))\n",
    "    }\n",
    "     # This structure tries to identify whether certain 'variables' exist in the table,\n",
    "     # they follow the same structure but some don't have values stored in them and these ones are not supposed to be saved, so there is less data.\n",
    "    if resp2.get('races'):\n",
    "         trait_data['races'] = [item['name'] for item in resp2['races']]\n",
    "\n",
    "    if resp2.get('subraces'):\n",
    "         trait_data['subraces'] = [item['name'] for item in resp2['subraces']]\n",
    "\n",
    "    if resp2.get('proficiencies'):\n",
    "         trait_data['proficiencies'] = [item['name'] for item in resp2['proficiencies']]\n",
    "     \n",
    "     # At the end all of indices are saved into the dictionary.\n",
    "    dict_of_traits[entry['index']] = trait_data\n",
    "pprint.pprint(dict_of_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the establishment of the rule dictionary. \n",
    "url = \"https://www.dnd5eapi.co/api/2014/rules\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_rules = {}\n",
    "rule_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    rule_data = {\n",
    "        'name' : name,\n",
    "        'desc': \"\".join(preprocess_text(resp2['desc']))\n",
    "    }\n",
    "    # In some cases, the variables stored in the tables contain lists of dictionaries. So each dictionary is accessed and the name of the responding subsection is saved in a list.\n",
    "    if resp2.get('subsections'):\n",
    "         rule_data['subsection_in_rule_sections'] = [item['name'] for item in resp2['subsections']]\n",
    "\n",
    "    dict_of_rules[entry['index']] = rule_data\n",
    "pprint.pprint(dict_of_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the establishment of the spell dictionary.\n",
    "url = \"https://www.dnd5eapi.co/api/2014/spells\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_spells = {}\n",
    "spell_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    spell_data = {\n",
    "        'name' : name,\n",
    "        'desc': \"\".join(preprocess_text(resp2['desc'])),\n",
    "        'range': resp2['range'],\n",
    "        'components':resp2['components'],\n",
    "        'ritual':resp2['ritual'],\n",
    "        'duration': resp2['duration'],\n",
    "        'concentration': resp2['concentration'],\n",
    "        'casting_time': resp2['casting_time'],\n",
    "        'level': resp2['level'],\n",
    "        'school_of_magic': [resp2['school']['name']],\n",
    "        'classes': [item['name'] for item in resp2['classes']],\n",
    "    }\n",
    "\n",
    "    if resp2.get('material'):\n",
    "         spell_data['material'] = resp2['material']\n",
    "\n",
    "    if resp2.get('subclasses'):\n",
    "        spell_data['subclasses'] = [item['name'] for item in resp2['subclasses']]\n",
    "\n",
    "    if resp2.get('higher_level'):\n",
    "        spell_data['higher_level'] = resp2['higher_level']\n",
    "\n",
    "    if resp2.get('damage'):\n",
    "        slot_level_damage = {}\n",
    "        if 'damage_type' in resp2['damage']:\n",
    "            spell_data['damage_type'] = [resp2['damage']['damage_type']['name']]\n",
    "        if 'damage_at_slot_level' in resp2['damage']:\n",
    "            for slot_level, damage in resp2['damage']['damage_at_slot_level'].items():\n",
    "                slot_level_damage[slot_level] = damage\n",
    "            spell_data['damage_at_slot_level'] = slot_level_damage \n",
    "\n",
    "    if resp2.get('atack_type'):\n",
    "       spell_data['attack_type'] = resp2['attack_type']\n",
    "    \n",
    "    dict_of_spells[entry['index']] = spell_data\n",
    "pprint.pprint(dict_of_spells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell handles the different races a player can be:\n",
    "url = \"https://www.dnd5eapi.co/api/2014/races\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_races = {}\n",
    "race_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "\n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    bonus_dict = {}\n",
    "    for item in resp2['ability_bonuses']:\n",
    "        bonus_dict[item['ability_score']['name']] = item['bonus']\n",
    "    \n",
    "    race_data = {\n",
    "        'name' : name,\n",
    "        'speed': resp2['speed'],\n",
    "        'ability_bonuses': bonus_dict,\n",
    "        'alignment': resp2['alignment'],\n",
    "        'age': resp2['age'],\n",
    "        'size': resp2['size'],\n",
    "        'size_description': resp2['size_description'],\n",
    "        'languages': [item['name'] for item in resp2['languages']],\n",
    "        'language_description': resp2['language_desc'],\n",
    "        'traits': [item['name'] for item in resp2['traits']],\n",
    "    }\n",
    "\n",
    "    if resp2.get('subraces') :\n",
    "         race_data['subraces'] = [item['name'] for item in resp2['subraces']]\n",
    "\n",
    "    if resp2.get('starting_proficiencies'):\n",
    "        race_data['starting_proficiencies'] =  [item['name'] for item in resp2['starting_proficiencies']]\n",
    "\n",
    "\n",
    "        \n",
    "    dict_of_races[entry['index']] = race_data\n",
    "\n",
    "pprint.pprint(dict_of_races)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dnd5eapi.co/api/2014/subraces\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_subraces = {}\n",
    "subraces_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    subraces_data = {\n",
    "        'name' : name,\n",
    "        'desc': \"\".join(preprocess_text(resp2['desc'])),\n",
    "        'race': resp2['race']['name'],\n",
    "        'ability_bonuses': bonus_dict,\n",
    "        'racial_traits': [item['name'] for item in resp2['racial_traits']],\n",
    "    }\n",
    "\n",
    "    if resp2.get('starting_proficiencies'):\n",
    "        subraces_data['starting_proficiencies'] = [item['name'] for item in resp2['starting_proficiencies']]\n",
    "\n",
    "    if resp2.get('languages'):\n",
    "        subraces_data['languages'] = resp2['languages']\n",
    "\n",
    "    if resp2.get('language_options'):\n",
    "        languages = resp2['language_options']['from']['options']\n",
    "        language_names = [lang['item']['name'] for lang in languages]\n",
    "        subraces_data['language_options'] = language_names\n",
    "\n",
    "    bonus_dict = {}\n",
    "    for item in resp2['ability_bonuses']:\n",
    "        bonus_dict[item['ability_score']['name']] = item['bonus'] \n",
    "\n",
    "    dict_of_subraces[entry['index']] = subraces_data\n",
    "    \n",
    "\n",
    "pprint.pprint(dict_of_subraces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e089c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dnd5eapi.co/api/2014/proficiencies\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_proficiencies = {}\n",
    "proficiency_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    proficiency_data = {\n",
    "        'name' : name,\n",
    "        'type' : resp2['type'],\n",
    "    }\n",
    "\n",
    "    if resp2.get('classes'):\n",
    "         proficiency_data['classes'] = [item['name'] for item in resp2['classes']]\n",
    "\n",
    "    if resp2.get('races'):\n",
    "        proficiency_data['races'] = [item['name'] for item in resp2['races']]\n",
    "\n",
    "    dict_of_proficiencies[entry['index']] = proficiency_data\n",
    "pprint.pprint(dict_of_proficiencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dnd5eapi.co/api/2014/equipment\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "dict_of_equipment = {}\n",
    "equipment_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name_of_equip = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "    \n",
    "    equipment_data =  {\n",
    "        'name' : name_of_equip,\n",
    "        'equipment-category': resp2['equipment_category']['name'],\n",
    "        'gear-category': resp2.get('gear_category',{}).get('name')\n",
    "    }\n",
    "\n",
    "    if resp2.get('desc'):\n",
    "         equipment_data['desc'] = \"\".join(preprocess_text(resp2['desc']))\n",
    "\n",
    "    if resp2.get('special'):\n",
    "         equipment_data['special'] = resp2['special']\n",
    "\n",
    "    if resp2.get('properties'):\n",
    "         equipment_data['properties'] = [item['name'] for item in resp2['properties']]\n",
    "\n",
    "    if resp2.get('contents'):\n",
    "        equipment_data['contents'] = [{'name': item['item']['name']} for item in resp2['contents']]\n",
    "\n",
    "    dict_of_equipment[entry['index']] = equipment_data\n",
    "pprint.pprint(dict_of_equipment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689348d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dnd5eapi.co/api/2014/features\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_features = {}\n",
    "feature_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    \n",
    "    time.sleep(DELAY)\n",
    "\n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    feature_data = {\n",
    "        'name' : entry['name'],\n",
    "        'desc' : \"\".join(preprocess_text(resp2['desc'])),\n",
    "        'class': resp2['class']['name'],\n",
    "        'level': resp2['level']\n",
    "    }\n",
    "\n",
    "    if resp2.get('prerequisites'):\n",
    "        feature_data['prerequisites'] =  resp2['prerequisites']\n",
    "    \n",
    "    dict_of_features[entry['index']] = feature_data\n",
    "pprint.pprint(dict_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ad130",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dnd5eapi.co/api/2014/magic-items\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_magic_items = {}\n",
    "item_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name_of_item = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    item_data = {\n",
    "        'name' : entry['name'],\n",
    "        'desc' : \"\".join(preprocess_text(resp2['desc'])),\n",
    "        'equipment-category': resp2['equipment_category']['name'],\n",
    "        'rarity': resp2['rarity']['name'],\n",
    "    }\n",
    "\n",
    "    if resp2.get('variants'):\n",
    "         item_data['variants'] = [item['name'] for item in resp2['variants']]\n",
    "\n",
    "    dict_of_magic_items[entry['index']] = item_data\n",
    "pprint.pprint(dict_of_magic_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dnd5eapi.co/api/2014/monsters\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_monsters = {}\n",
    "monster_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name_of_monster = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    senses = {}\n",
    "    for key, value in resp2['senses'].items():\n",
    "        senses[key] = value\n",
    "    \n",
    "    movement = {}\n",
    "    for key, value in resp2['speed'].items():\n",
    "        movement[key] = value\n",
    "\n",
    "    monster_data = {\n",
    "        'name' : name_of_monster,\n",
    "        'size': resp2['size'],\n",
    "        'type':resp2['type'],\n",
    "        'alignment': resp2['alignment'],\n",
    "        'hit_points':resp2['hit_points'],\n",
    "        'hit_dice':resp2['hit_dice'],\n",
    "        'hit_points_roll': resp2['hit_points_roll'],\n",
    "        'speed': movement,\n",
    "        'strength': resp2['strength'],\n",
    "        'dexterity':resp2['dexterity'],\n",
    "        'constitution': resp2['constitution'],\n",
    "        'intelligence': resp2['intelligence'],\n",
    "        'wisdom': resp2['wisdom'],\n",
    "        'charisma': resp2['charisma'],\n",
    "        'senses': senses,\n",
    "        'languages': resp2['languages'],\n",
    "        'challenge_rating': resp2['challenge_rating'],\n",
    "        'proficiency_bonus': resp2['proficiency_bonus'],\n",
    "        'gained_experience': resp2['xp']\n",
    "    }\n",
    "\n",
    "    if resp2.get('armor_class'):\n",
    "       armor_class = {}\n",
    "       for item in resp2['armor_class']:\n",
    "            armor_class[item['type']] = item['value']\n",
    "       monster_data['armor_class'] = armor_class\n",
    "\n",
    "    if resp2.get('damage_vulnerabilities'):\n",
    "        monster_data['damage_vulnerabilites'] = resp2['damage_vulnerabilities']\n",
    "\n",
    "    if resp2.get('damage_resistances'):\n",
    "        monster_data['damage_resistances'] = resp2['damage_resistances']\n",
    "    \n",
    "    if resp2.get('damage_immunities'):\n",
    "        monster_data['damage_immunities'] = resp2['damage_immunities']\n",
    "\n",
    "    if resp2.get('condition_immunities'):\n",
    "        monster_data['condition_immunities'] = [item['name'] for item in resp2['condition_immunities']]\n",
    "\n",
    "    if resp2.get('special_abilites'):\n",
    "        special = {}\n",
    "        for items in resp2['special_abilities']:\n",
    "            special['name'] = items['name']\n",
    "            special['desc'] = items['desc']\n",
    "            if 'damage' in items:\n",
    "                special['damage'] = items['damage']\n",
    "            if 'dc' in items:\n",
    "                dc = {}\n",
    "                dc['name'] = items['dc']['dc_type']['name']\n",
    "                dc['value'] = items['dc']['dc_value']\n",
    "                special['dc'] = dc\n",
    "        monster_data['special_abilities'] = special\n",
    "    \n",
    "    if resp2.get('actions'):\n",
    "        for items in resp2['actions']:\n",
    "            actions = {}\n",
    "            actions['name'] = items['name']\n",
    "            actions['desc'] = items['desc']\n",
    "        monster_data['actions'] = actions\n",
    "\n",
    "    if resp2.get('legendary_actions'):\n",
    "        legendary = {}\n",
    "        for items in resp2['legendary_actions']:\n",
    "            legendary['name'] = items['name']\n",
    "            legendary['action_desc'] = items['desc']\n",
    "        monster_data['legendary_actions'] = legendary\n",
    "\n",
    "    if resp2.get('forms'):\n",
    "        monster_data['forms'] = [item['name'] for item in resp2['forms']]\n",
    "\n",
    "    if resp2.get('reactions'):\n",
    "        reactions = {}\n",
    "        for item in resp2['reactions']:\n",
    "             reactions['name'] = item['name']\n",
    "             reactions['desc'] = item['desc']\n",
    "        monster_data['reactions'] = reactions\n",
    "    \n",
    "    proficiency_monster = {}\n",
    "    if resp2.get('proficiencies'):\n",
    "        for items in resp2['proficiencies']:\n",
    "            proficiency_monster[items['proficiency']['name']] = items['value']\n",
    "        monster_data['proficiencies'] = proficiency_monster\n",
    "\n",
    "    dict_of_monsters[entry['index']] = monster_data\n",
    "# pprint.pprint(dict_of_monsters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dnd5eapi.co/api/2014/equipment-categories\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_equipment_categories = {}\n",
    "category_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    category_data = {\n",
    "        'name' : name\n",
    "    }\n",
    "\n",
    "    if resp2.get('equipment'):\n",
    "        category_data['type'] = [item['name'] for item in resp2['equipment']]\n",
    "\n",
    "   \n",
    "    dict_of_equipment_categories[entry['index']] = category_data\n",
    "    \n",
    "\n",
    "pprint.pprint(dict_of_equipment_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e96b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dnd5eapi.co/api/2014/backgrounds\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "resp = response.json()\n",
    "\n",
    "dict_of_backgrounds = {}\n",
    "background_data = {}\n",
    "\n",
    "for entry in resp['results']:\n",
    "    name = entry['name']\n",
    "\n",
    "    time.sleep(DELAY)\n",
    "    \n",
    "    response2 = requests.request(\"GET\", url+f\"/{entry['index']}\", headers=headers, data=payload)\n",
    "    resp2 = response2.json()\n",
    "\n",
    "    background_data = {\n",
    "        'name' : name\n",
    "    }\n",
    "\n",
    "    if resp2.get('starting_proficiencies'):\n",
    "        background_data['starting_proficiencies'] = [item['name'] for item in resp2['starting_proficiencies']]\n",
    "\n",
    "    if resp2.get('language_options'):\n",
    "        background_data['language_options'] = resp2['language_options']['choose']\n",
    "\n",
    "    if resp2.get('starting_equipment'):\n",
    "        background_data['starting_equipment'] = [item['equipment']['name'] for item in resp2['starting_equipment']]\n",
    "\n",
    "    if resp2.get('starting_equipment_options'):\n",
    "        starting_equip_options = {}\n",
    "        starting_equip_options['choose'] = [item['choose'] for item in resp2['starting_equipment_options']]\n",
    "        starting_equip_options['equipment_options'] = [item['from']['equipment_category']['name'] for item in resp2['starting_equipment_options']]\n",
    "        background_data['starting_equipment_options'] = starting_equip_options\n",
    "\n",
    "    personality = { 'options':[] } \n",
    "    personality['amount_of_options'] = resp2['personality_traits']['choose'] \n",
    "    for item in resp2['personality_traits']['from']['options']: \n",
    "        personality['options'].append(item['string'])\n",
    "    background_data['personality_traits'] = personality\n",
    "\n",
    "    if resp2.get('feature'):\n",
    "        feat_dict = {}\n",
    "        feat_dict['name'] = resp2['feature']['name']\n",
    "        feat_dict['desc'] =  \"\".join(resp2['feature']['desc'])\n",
    "        background_data['feature'] = feat_dict\n",
    "\n",
    "    if resp2.get('ideals'):\n",
    "        ideals = {}\n",
    "        ideals['choose'] = resp2['ideals']['choose']\n",
    "        ideal_option = {}\n",
    "        ideals['possible_ideals'] = []\n",
    "        for item in resp2['ideals']['from']['options']:\n",
    "            ideal_option['desc'] = item['desc']\n",
    "            ideal_option['alignments'] = [item['name'] for item in item['alignments']]\n",
    "            ideals['possible_ideals'].append(ideal_option)\n",
    "        background_data['ideals'] = ideals\n",
    "    \n",
    "    if resp2.get('bonds'):\n",
    "        bonds = {}\n",
    "        bonds['choose'] = resp2['bonds']['choose']\n",
    "        bonds['bond_options'] = [item['string'] for item in resp2['bonds']['from']['options']]\n",
    "        background_data['bonds'] = bonds\n",
    "\n",
    "    if resp2.get('flaws'):\n",
    "        flaws = {}\n",
    "        flaws['choose'] = resp2['flaws']['choose']\n",
    "        flaws['flaw_options'] = [item['string'] for item in resp2['flaws']['from']['options']]\n",
    "        background_data['flaws'] = flaws\n",
    "\n",
    "    dict_of_backgrounds[entry['index']] = background_data\n",
    "    \n",
    "\n",
    "pprint.pprint(dict_of_backgrounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all dicts will be saved into the api_data.json. In order to structure the data in the json itself, a new dict is constructed, saving each dictionary under a thematically responding key. \n",
    "file_path = 'api_data/api_data.json'\n",
    "json_dict = {\n",
    "            'rules': dict_of_rules,\n",
    "            'rule_sections': dict_of_rule_sections,\n",
    "            'races': dict_of_races,\n",
    "            'subraces': dict_of_subraces,\n",
    "            'classes': dict_of_classes,\n",
    "            'subclasses': dict_of_subclasses,\n",
    "            'skills': dict_of_skills,\n",
    "            'feats': dict_of_feats,\n",
    "            'languages': dict_of_languages,\n",
    "            'ability_scores': dict_of_ability_scores,\n",
    "            'traits': dict_of_traits,\n",
    "            'proficiencies': dict_of_proficiencies,\n",
    "            'features': dict_of_features,\n",
    "            'example_character_background': dict_of_backgrounds,\n",
    "            'conditions': dict_of_conditions,\n",
    "            'equipment': dict_of_equipment,\n",
    "            'equipment_categories': dict_of_equipment_categories,\n",
    "            'weapon_properties': dict_of_weapon_properties,\n",
    "            'magic_items': dict_of_magic_items,\n",
    "            'magic_schools': dict_of_magic_schools,\n",
    "            'damage_types': dict_of_damage_types,\n",
    "            'spells': dict_of_spells,\n",
    "            'monsters': dict_of_monsters\n",
    "        }\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    # The previously constructed dictionary is written to the json file:\n",
    "    json.dump(json_dict,\n",
    "        indent=4, # For better readability and visible structure four indents are added.\n",
    "        ensure_ascii=False, # This is set to false, so f.ex. apostrophes aren't converted.\n",
    "        fp=f\n",
    "    )\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db84c0d",
   "metadata": {},
   "source": [
    "### The next steps ###\n",
    "\n",
    "What has to be done next is create a dataset and then document store out of our completed json-file, that later is used to retrieve information. However to make the important field 'desc' and 'name' our later retrieved information source and the other fields our meta-data-fields, we need our json-dict to follow the format:\n",
    "\n",
    "dict: {\n",
    "    'content': 'desc',\n",
    "    'meta_data': every other field containig information\n",
    "}\n",
    "\n",
    "Also a new meta-data field called 'category' is added for better response filtering later on. The category variable orients itself on the key given to each dictionary entry in the previous dictionary.\n",
    "\n",
    "### The sentence and later retrieval transformer: ###\n",
    "multi-qa-distilbert-cos-v1 \t(\"This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources. For an introduction to semantic search, have a look at: SBERT.net - Semantic Search\" - https://huggingface.co/sentence-transformers/multi-qa-distilbert-cos-v1) - as it has a word limit of 512 word, before writing the documents to the Document store they are split in accordingly sized token chunks with a token overlap of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590e3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path variables.\n",
    "file_path_rag = 'api_data/rag_data.json'\n",
    "file_path = 'api_data/api_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f919dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to not reaccess the api and reload each dictionary, the already structured file is used to re-structure the rag-file into the desired format:\n",
    "with open(file_path, 'r') as f:\n",
    "    api_info = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "# Every category that saves each loaded dict is added into the metadata to relieve later filtering.\n",
    "def convertToRAGFormat (information):\n",
    "    expected_docs = []\n",
    "    for category, dicts in information.items():\n",
    "        for index, items in dicts.items():\n",
    "            later_content = []\n",
    "            later_content.append(items.get('name'))\n",
    "            if items.get('desc'):\n",
    "                later_content.append(items.get('desc'))\n",
    "            if items.get('alignment'):\n",
    "                later_content.append(items.get('alignment'))\n",
    "            if items.get('language_description'):\n",
    "                later_content.append(items.get('language_description'))\n",
    "\n",
    "            meta_info = {intern_key: intern_value for intern_key, intern_value in items.items() if intern_key != 'desc' and intern_key != 'alignment' and intern_key != 'language_description'}\n",
    "            each_doc = {\n",
    "                'content': '. '.join(later_content),\n",
    "                'meta': {**meta_info,'category': category}\n",
    "            }\n",
    "            expected_docs.append(each_doc)\n",
    "    \n",
    "    return expected_docs\n",
    "\n",
    "rag_docs = convertToRAGFormat(api_info)\n",
    "with open(file_path_rag, 'w') as fr:\n",
    "    json.dump(rag_docs, indent=4, ensure_ascii=False, fp=fr)\n",
    "    fr.close()\n",
    "    # The ascii-encoding is set to false, so f.ex. apostrophes aren't converted and can later be filtered if neccessary.\n",
    "    # For better readability and visible structure four indents are added.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Pipeline parts:\n",
    "document_store = InMemoryDocumentStore()\n",
    "document_joiner = DocumentJoiner(join_mode='reciprocal_rank_fusion')\n",
    "document_splitter = DocumentSplitter(split_by=\"word\", split_length=512, split_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906e0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to be able to use the LLM, that api key is used here:\n",
    "os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyD3Bb1km908nqdn39vE_0RT-hhWHFtcOJ4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7129e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    }
   ],
   "source": [
    "# In order to save each entry in the dicts, the file is re-opened and every entry is saved as a document with the new format that was previously constructed, strucutring the document into 'content' and 'meta'-data.\n",
    "with open(file_path_rag, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]\n",
    "print(len(docs)) # In order to check whether some docs have been lost, the length of the docs-list will be printed out.\n",
    "\n",
    "# In order to be able to use every single meta-data key entry that is supposed to be embedded with the corresponding content, every single key is added to a set.\n",
    "# First an empty set is initialized.\n",
    "meta_keys = set()\n",
    "# Then for every document in the document-list, the keys are added to the set, if they aren't already contained via the update()-method.\n",
    "for doc in docs:\n",
    "    meta_keys.update(doc.meta.keys())\n",
    "# After that the set is converted to a list, so that it can be added to the doc_embedder so that all the meta-fields are includded im the embdding too.\n",
    "meta_keys = list(meta_keys)\n",
    "\n",
    "# If desired they can be looked at here:\n",
    "# print(meta_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d19da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the entries have to be embedded with an embedder:\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model='multi-qa-distilbert-cos-v1', meta_fields_to_embed=meta_keys)\n",
    "doc_embedder.warm_up()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8742043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 66/66 [02:22<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# Before embedding the documents and adding them to the document store, they are split into chunks with the document_splitter:\n",
    "split_docs = document_splitter.run(docs)\n",
    "docs_w_embeddings = doc_embedder.run(split_docs['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it needs to be checked whether all metadata was considered:\n",
    "embedded_docs = docs_w_embeddings['documents']\n",
    "# with this, the correct length of all embeddings can be checked and they are all 768 dimension long as described in the official documentation: https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "#for doc in embedded_docs:\n",
    "    #print(len(doc.embedding))\n",
    "print(embedded_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a44b654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2098"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the embedded documents are added to the document store:\n",
    "document_store.write_documents(docs_w_embeddings[\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7447742",
   "metadata": {},
   "source": [
    "# RAG-Pipeline #\n",
    "\n",
    "This pipeline contains apart from the standard parts (textual embedder, llm, promptbuilder, retriever) a BM25-retriever to construct a hybrid search as well as dense retriever in order to boost results.\n",
    " Results from both retrievers get joined with the Document joiner and ranked according to their score.\n",
    "However even with the hybrid search a filtering mechanism is still needed. Without a filtering mechanism, a reliable finding of resources will not work reliably because of the dynamic and homogenous naming of metadata fields. \n",
    "\n",
    "Queries like : 'What races can I play as?' return every single document, that somewhere contains the word 'race' in it's meta-data. This is often the case when looking at race-related skill or race-related weapons or classes. To alleviate this effect the key 'catgegory' from the api_data.json has been selected to function as a filter. \n",
    "\n",
    "An improved filtering mechanism could be possible with for example a multi-label classifier, however this would need a lot of training data, which is not accessible in this contenxt. Another mechanism other than hard-coding filtering rules, would be by letting an LLM decide which category/categories the question falls into. As our chosen LLM only provides 5 calls per day (similar to other free plans of LLMs), we did not integrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e1d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ChatPromptBuilder has 3 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n",
      "ChatPromptBuilder has 3 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    }
   ],
   "source": [
    "template = [\n",
    "    ChatMessage.from_user(\n",
    "        \"\"\"\n",
    "You are a D&D expert. Given the following information, answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "Metadata:\n",
    "{% for key, value in document.meta.items() %}\n",
    "    {{ key }}: {{ value }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt_builder_hybrid = ChatPromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e230faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_generator_hybrid = GoogleGenAIChatGenerator(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_model = 'cross-encoder/ms-marco-TinyBERT-L2-v2'\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model='multi-qa-distilbert-cos-v1')\n",
    "text_embedder_retr = SentenceTransformersTextEmbedder(model='multi-qa-distilbert-cos-v1')\n",
    "\n",
    "embedding_retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "embedding_retriever_retr = InMemoryEmbeddingRetriever(document_store)\n",
    "\n",
    "bm25_retriever = InMemoryBM25Retriever(document_store)\n",
    "bm25_retriever_retr = InMemoryBM25Retriever(document_store)\n",
    "\n",
    "ranker = SentenceTransformersSimilarityRanker(model=cross_model)\n",
    "ranker_retr = SentenceTransformersSimilarityRanker(model=cross_model)\n",
    "\n",
    "document_joiner_retr = DocumentJoiner(join_mode='reciprocal_rank_fusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c243fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000016981CBF340>\n",
       " Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - embedding_retriever: InMemoryEmbeddingRetriever\n",
       "  - bm25_retriever: InMemoryBM25Retriever\n",
       "  - document_joiner: DocumentJoiner\n",
       "  - ranker: SentenceTransformersSimilarityRanker\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: GoogleGenAIChatGenerator\n",
       " Connections\n",
       "  - text_embedder.embedding -> embedding_retriever.query_embedding (list[float])\n",
       "  - embedding_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - bm25_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - document_joiner.documents -> ranker.documents (list[Document])\n",
       "  - ranker.documents -> prompt_builder.documents (list[Document])\n",
       "  - prompt_builder.prompt -> llm.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete pipeline including the LLM\n",
    "hybrid_retrieval = Pipeline()\n",
    "hybrid_retrieval.add_component(\"text_embedder\", text_embedder)\n",
    "hybrid_retrieval.add_component(\"embedding_retriever\", embedding_retriever)\n",
    "hybrid_retrieval.add_component(\"bm25_retriever\", bm25_retriever)\n",
    "hybrid_retrieval.add_component(\"document_joiner\", document_joiner)\n",
    "hybrid_retrieval.add_component(\"ranker\", ranker)\n",
    "\n",
    "# new:\n",
    "hybrid_retrieval.add_component(\"prompt_builder\", prompt_builder_hybrid)\n",
    "hybrid_retrieval.add_component(\"llm\", chat_generator_hybrid)\n",
    "\n",
    "hybrid_retrieval.connect(\"text_embedder\", \"embedding_retriever\")\n",
    "hybrid_retrieval.connect('bm25_retriever','document_joiner')\n",
    "hybrid_retrieval.connect('embedding_retriever', 'document_joiner')\n",
    "hybrid_retrieval.connect(\"document_joiner\", \"ranker\")\n",
    "\n",
    "# new:\n",
    "hybrid_retrieval.connect(\"ranker\", \"prompt_builder\")\n",
    "hybrid_retrieval.connect(\"prompt_builder.prompt\", \"llm.messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "179251b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x000001698266C880>\n",
       " Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - embedding_retriever: InMemoryEmbeddingRetriever\n",
       "  - bm25_retriever: InMemoryBM25Retriever\n",
       "  - document_joiner: DocumentJoiner\n",
       "  - ranker: SentenceTransformersSimilarityRanker\n",
       " Connections\n",
       "  - text_embedder.embedding -> embedding_retriever.query_embedding (list[float])\n",
       "  - embedding_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - bm25_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - document_joiner.documents -> ranker.documents (list[Document])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to evaluate the results from retrieval, the exact same pipeline was built in order to acces the ranked results before the LLM tries to build a prompt:\n",
    "hb_nollm_pipeline = Pipeline()\n",
    "hb_nollm_pipeline.add_component(\"text_embedder\", text_embedder_retr)\n",
    "hb_nollm_pipeline.add_component(\"embedding_retriever\", embedding_retriever_retr)\n",
    "hb_nollm_pipeline.add_component(\"bm25_retriever\", bm25_retriever_retr)\n",
    "hb_nollm_pipeline.add_component(\"document_joiner\", document_joiner_retr)\n",
    "hb_nollm_pipeline.add_component(\"ranker\", ranker_retr)\n",
    "\n",
    "hb_nollm_pipeline.connect(\"text_embedder\", \"embedding_retriever\")\n",
    "hb_nollm_pipeline.connect('bm25_retriever','document_joiner')\n",
    "hb_nollm_pipeline.connect('embedding_retriever', 'document_joiner')\n",
    "hb_nollm_pipeline.connect(\"document_joiner\", \"ranker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf3754ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 1/1 [00:00<00:00, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: High Elf. As a high elf  you have a keen mind and a mastery of at least the basics of magic. In many fantasy gaming worlds  there are two kinds of high elves. One type is haughty and reclusive  believing themselves to be superior to non elves and even other elves. The other type is more common and more friendly  and often encountered among humans and other races.\n",
      "Metadata: subraces\n",
      "final document score: 0.04780599847435951\n",
      "----\n",
      "Content: Elf. Elves love freedom, variety, and self-expression, so they lean strongly toward the gentler aspects of chaos. They value and protect others' freedom as well as their own, and they are more often good than not.. You can speak, read, and write Common and Elvish. Elvish is fluid, with subtle intonations and intricate grammar. Elven literature is rich and varied, and their songs and poems are famous among other races. Many bards learn their language so they can add Elvish ballads to their repertoires.\n",
      "Metadata: races\n",
      "final document score: 0.0008482832345180213\n",
      "----\n",
      "Content: Lightfoot Halfling. As a lightfoot halfling  you can easily hide from notice  even using other people as cover. You're inclined to be affable and get along well with others. Lightfoots are more prone to wanderlust than other halflings  and often dwell alongside other races or take up a nomadic life.\n",
      "Metadata: subraces\n",
      "final document score: 0.0003931829705834389\n",
      "----\n",
      "Content: Find the Path. This spell allows you to find the shortest  most direct physical route to a specific fixed location that you are familiar with on the same plane of existence. If you name a destination on another plane of existence  a destination that moves such as a mobile fortress  or a destination that isn't specific such as \"a green dragon's lair\"  the spell fails. For the duration  as long as you are on the same plane of existence as the destination  you know how far it is and in what direction it lies. While you are traveling there  whenever you are presented with a choice of paths along the way  you automatically determine which path is the shortest and most direct route but not necessarily the safest route to the destination.\n",
      "Metadata: spells\n",
      "final document score: 4.0923565393313766e-05\n",
      "----\n",
      "Content: illusion. Illusion spells deceive the senses or minds of others. They cause people to see things that are not there  to miss things that are there  to hear phantom noises  or to remember things that never happened. Some illusions create phantom images that any creature can see  but the most insidious illusions plant an image directly in the mind of a creature.\n",
      "Metadata: magic_schools\n",
      "final document score: 1.9671952031785622e-05\n",
      "----\n",
      "Content: Draconic Ancestry (Black). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "final document score: 1.3460298760037404e-05\n",
      "----\n",
      "Content: Draconic Ancestry (White). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "final document score: 1.3428372767521068e-05\n",
      "----\n",
      "Content: Darkvision. You have superior vision in dark and dim conditions. You can see in dim light within 60 feet of you as if it were bright light  and in darkness as if it were dim light. You cannot discern color in darkness  only shades of gray.\n",
      "Metadata: traits\n",
      "final document score: 1.2312432772887405e-05\n",
      "----\n",
      "Content: Kobold. lawful evil\n",
      "Metadata: monsters\n",
      "final document score: 1.2089719348296057e-05\n",
      "----\n",
      "Content: Fey Ancestry. You have advantage on saving throws against being charmed  and magic cannot put you to sleep.\n",
      "Metadata: traits\n",
      "final document score: 1.1268147318332922e-05\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"what races are there?\"\n",
    "result = hb_nollm_pipeline.run(\n",
    "    {\"text_embedder\": {\"text\": query}, \"bm25_retriever\": {\"query\": query, \"top_k\":5}, \"embedding_retriever\": {\"top_k\": 5}, \"ranker\": {\"query\": query}}\n",
    ")\n",
    "for doc in result['ranker']['documents']:\n",
    "    print(\"Content:\", doc.content)\n",
    "    print(\"Metadata:\", doc.meta['category'])\n",
    "    print('final document score:', doc.score)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490788fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"tell me about barbarian levels?\"\n",
    "\n",
    "result = hybrid_retrieval.run(\n",
    "    {\"text_embedder\": {\"text\": query}, \"bm25_retriever\": {\"query\": query}, \"ranker\": {\"query\": query}, 'prompt_builder': {'query': query}}\n",
    ")\n",
    "# hybrid_retrieval.draw(\"hybrid-retrieval.png\")\n",
    "# print(result[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f7b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 1/1 [00:00<00:00, 42.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: Draconic Ancestry (White). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5011509764689459\n",
      "----\n",
      "Content: Darkvision. You have superior vision in dark and dim conditions. You can see in dim light within 60 feet of you as if it were bright light  and in darkness as if it were dim light. You cannot discern color in darkness  only shades of gray.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5011092888124974\n",
      "----\n",
      "Content: Draconic Ancestry (Black). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5011036141695698\n",
      "----\n",
      "Content: Draconic Ancestry (Green). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5010216868839156\n",
      "----\n",
      "Content: Draconic Ancestry (Gold). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5010214477383379\n",
      "----\n",
      "Content: Draconic Ancestry (Bronze). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5010115171015418\n",
      "----\n",
      "Content: Draconic Ancestry (Blue). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5010020216044284\n",
      "----\n",
      "Content: Draconic Ancestry (Red). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5010003718921046\n",
      "----\n",
      "Content: Fey Ancestry. You have advantage on saving throws against being charmed  and magic cannot put you to sleep.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5009807868403165\n",
      "----\n",
      "Content: Draconic Ancestry (Silver). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5009782387858986\n",
      "----\n",
      "Content: Draconic Ancestry (Copper). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5009643006688319\n",
      "----\n",
      "Content: Draconic Ancestry. You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5009437559834674\n",
      "----\n",
      "Content: Draconic Ancestry (Brass). You have draconic ancestry. Choose one type of dragon from the Draconic Ancestry table. Your breath weapon and damage resistance are determined by the dragon type  as shown in the table.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5009348026344028\n",
      "----\n",
      "Content: Tiefling. Tieflings might not have an innate tendency toward evil, but many of them end up there. Evil or not, an independent nature inclines many tieflings toward a chaotic alignment.. You can speak, read, and write Common and Infernal.\n",
      "Metadata: races\n",
      "similarity/fitness: 0.5009116383989995\n",
      "----\n",
      "Content: Damage Resistance. You have resistance to the damage type associated with your draconic ancestry.\n",
      "Metadata: traits\n",
      "similarity/fitness: 0.5009003452961126\n",
      "----\n",
      "Content: High Elf. As a high elf  you have a keen mind and a mastery of at least the basics of magic. In many fantasy gaming worlds  there are two kinds of high elves. One type is haughty and reclusive  believing themselves to be superior to non elves and even other elves. The other type is more common and more friendly  and often encountered among humans and other races.\n",
      "Metadata: subraces\n",
      "similarity/fitness: 0.5008760331677377\n",
      "----\n",
      "Content: Wererat, Rat Form. lawful evil\n",
      "Metadata: monsters\n",
      "similarity/fitness: 0.5008530988203828\n",
      "----\n",
      "Content: Wererat, Hybrid Form. lawful evil\n",
      "Metadata: monsters\n",
      "similarity/fitness: 0.5008408027887101\n",
      "----\n",
      "Content: Lightfoot Halfling. As a lightfoot halfling  you can easily hide from notice  even using other people as cover. You're inclined to be affable and get along well with others. Lightfoots are more prone to wanderlust than other halflings  and often dwell alongside other races or take up a nomadic life.\n",
      "Metadata: subraces\n",
      "similarity/fitness: 0.500828006176931\n",
      "----\n",
      "Content: Sahuagin. lawful evil\n",
      "Metadata: monsters\n",
      "similarity/fitness: 0.5008254423054612\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d89828d2",
   "metadata": {},
   "source": [
    "## Applying filters ##\n",
    "\n",
    "Another more efficient way to automatically assign the correct category would be the using multi-label classification. This could assign 2 or more fitting labels to search queries. However as we don't have enough queries and data to train, the queries were constructed based on keyword-filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filters(question: str):\n",
    "    if \"race\" in question.lower() or \"races\" in question.lower():\n",
    "        print('race was chosen')\n",
    "        return  {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"races\"}\n",
    "    if \"weapon\" in question.lower():\n",
    "        print('weapon was chosen')\n",
    "        return {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"equipment-categories\"}\n",
    "    if \"spell\" in question.lower():\n",
    "        return {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"spells\"}\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b750a1",
   "metadata": {},
   "source": [
    "## Evaluation ## \n",
    "\n",
    "As the API used for this RAG QA pipeline is from 2014 and there have been some changes including new releases in the game and altercations, we worked with the API and therefore need to use queries that were real and similar in content. \n",
    "Some were from https://www.dndbeyond.com/?msockid=201f823801c3644c068896b30048651a\n",
    "\n",
    "As there aren't that many ways to get to the queries: \n",
    "- 3-5 queries per category (23 categories)\n",
    "\n",
    "Then haystack built in evaluation for the retrieval:\n",
    "- Recall@k and Precision@k\n",
    "- MMR \n",
    "\n",
    "For the LLM we used: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c78427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phython_fallstudien",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
